{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "1b2fa5b90e2146039ab7db6042d807ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_476d52a08e2d49498c9551b4af069c58",
              "IPY_MODEL_97a3e798433243a9a1d7b1089146da0f",
              "IPY_MODEL_2b6f9d5e1eff47779a02284727f334b8"
            ],
            "layout": "IPY_MODEL_97bd1c6695094b879787a9eeb96c3fbc"
          }
        },
        "476d52a08e2d49498c9551b4af069c58": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bec58b29df7b4a038ad2907b718ca683",
            "placeholder": "​",
            "style": "IPY_MODEL_6a63f753d34c4596988e35c182a828d1",
            "value": "100%"
          }
        },
        "97a3e798433243a9a1d7b1089146da0f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b4afd2810c64440a8af137f90bec34c2",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_05f47e428a9e46168dd032502112a5dd",
            "value": 1
          }
        },
        "2b6f9d5e1eff47779a02284727f334b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_677da5978e9a4bf4810f57b15479bb31",
            "placeholder": "​",
            "style": "IPY_MODEL_d8269de3766a47bb879db513e2857d0c",
            "value": " 1/1 [00:00&lt;00:00, 68.89it/s]"
          }
        },
        "97bd1c6695094b879787a9eeb96c3fbc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bec58b29df7b4a038ad2907b718ca683": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6a63f753d34c4596988e35c182a828d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b4afd2810c64440a8af137f90bec34c2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "05f47e428a9e46168dd032502112a5dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "677da5978e9a4bf4810f57b15479bb31": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d8269de3766a47bb879db513e2857d0c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install openai\n",
        "!pip install datasets\n",
        "!pip install transformers\n",
        "!pip install tqdm"
      ],
      "metadata": {
        "id": "vVw57ZcQMVJ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JW1f5EYLIf3g"
      },
      "outputs": [],
      "source": [
        "import openai\n",
        "import json\n",
        "from transformers import pipeline\n",
        "from tqdm import tqdm\n",
        "import csv\n",
        "openai.api_key = \"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\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%cd \"drive/MyDrive/gpt\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jWdWeeyb3PU6",
        "outputId": "ac2e86a6-53bf-4fa0-b51d-748a2575292d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/MyDrive/gpt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def zero_shot_sentiment_analysis_GPT_3(prompt, temperature=0.2, model_name = 'davinci'):\n",
        "    labels = [\"negative\", \"positive\", \"neutral\"]\n",
        "    message = \"\";\n",
        "    while (message not in labels):\n",
        "      completions = openai.Completion.create(\n",
        "          engine = model_name,\n",
        "          prompt = f\"Please analyze the following text for sentiment with only Neutral or Positive or Negative as output, no other discusion needed:\\n\\nText: {prompt}\\n\\nSentiment:\",\n",
        "          max_tokens=1,\n",
        "          n=1,\n",
        "          temperature = temperature,\n",
        "        # labels=labels\n",
        "      )\n",
        "      message = completions.choices[0].text.strip().lower()\n",
        "    if message == 'negative':\n",
        "      return 0\n",
        "    elif message == 'positive':\n",
        "      return 2\n",
        "    elif message == 'neutral':\n",
        "      return 1"
      ],
      "metadata": {
        "id": "O4vqF0w_JHLU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def zero_shot_sentiment_analysis_GPT_Neo(prompt, classifier):\n",
        "  classifier = classifier\n",
        "  result = classifier(prompt, ['positive', 'negative', 'neutral'])\n",
        "  label = result['labels'][0]\n",
        "  if label == 'negative':\n",
        "    return 0\n",
        "  elif label == 'positive':\n",
        "    return 2\n",
        "  elif label == 'neutral':\n",
        "    return 1\n",
        "\n"
      ],
      "metadata": {
        "id": "8pI8B3vjqN0v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test run\n",
        "prompt = \"The order comprises four ball mills , which will be organized in two different streams for treating ore in the Pilanesberg platinum mine .\"\n",
        "message = zero_shot_sentiment_analysis_GPT_3(prompt)\n",
        "print(message)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OlMf35esLz03",
        "outputId": "047ebf07-c293-4231-a92f-79e7a87623f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classifier = pipeline('zero-shot-classification', model='EleutherAI/gpt-neo-2.7B', device=0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MQhXqja_wydd",
        "outputId": "e5383f19-0540-4507-e2ed-d4d462560fad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of GPTNeoForSequenceClassification were not initialized from the model checkpoint at EleutherAI/gpt-neo-2.7B and are newly initialized: ['transformer.h.15.attn.attention.bias', 'transformer.h.23.attn.attention.bias', 'transformer.h.5.attn.attention.bias', 'transformer.h.17.attn.attention.bias', 'transformer.h.19.attn.attention.bias', 'transformer.h.31.attn.attention.bias', 'transformer.h.11.attn.attention.bias', 'transformer.h.3.attn.attention.bias', 'transformer.h.1.attn.attention.bias', 'transformer.h.13.attn.attention.bias', 'transformer.h.27.attn.attention.bias', 'transformer.h.29.attn.attention.bias', 'score.weight', 'transformer.h.7.attn.attention.bias', 'transformer.h.9.attn.attention.bias', 'transformer.h.25.attn.attention.bias', 'transformer.h.21.attn.attention.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Failed to determine 'entailment' label id from the label2id mapping in the model config. Setting to -1. Define a descriptive label2id mapping in the model config to ensure correct outputs.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# test run\n",
        "prompt = \"The order comprises four ball mills , which will be organized in two different streams for treating ore in the Pilanesberg platinum mine .\"\n",
        "message = zero_shot_sentiment_analysis_GPT_Neo(prompt, classifier)\n",
        "print(message)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TM3oETeO0dbL",
        "outputId": "68046fd9-2762-4e33-cc60-cac1b3740ebc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using pad_token, but it is not set yet.\n",
            "Tokenizer was not supporting padding necessary for zero-shot, attempting to use  `pad_token=eos_token`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "positive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset, DatasetDict\n",
        "# dataset load               \n",
        "dataset = load_dataset('financial_phrasebank', 'sentences_allagree')\n",
        "train_size = 0\n",
        "valid_size = 0\n",
        "test_size = 1\n",
        "dataset_dict = DatasetDict({\n",
        "    'train': dataset['train'].select(range(int(len(dataset['train']) * train_size))),\n",
        "    'validation': dataset['train'].select(range(int(len(dataset['train']) * train_size), int(len(dataset['train']) * (train_size + valid_size)))),\n",
        "    'test': dataset['train'].select(range(int(len(dataset['train']) * (1 - test_size)), len(dataset['train'])))\n",
        "})\n",
        "\n",
        "#test\n",
        "output_path = 'gpt-neo.csv'\n",
        "preds = []\n",
        "labels = []\n",
        "sentence = []\n",
        "for row in tqdm(dataset_dict['test']):\n",
        "    sentence.append(row['sentence'])\n",
        "    labels.append(row['label'])\n",
        "    preds.append(zero_shot_sentiment_analysis_GPT_Neo(row['sentence'],classifier))\n",
        "\n",
        "# Write the predictions and performance metrics to a CSV file\n",
        "with open(output_path, \"w\", newline=\"\") as f:\n",
        "    writer = csv.writer(f)\n",
        "    writer.writerow([\"sentence\", \"true_label\", \"pred_label\"])\n",
        "    for i in range(len(preds)):\n",
        "        writer.writerow([dataset_dict['test'][i]['sentence'], labels[i], preds[i]])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 146,
          "referenced_widgets": [
            "1b2fa5b90e2146039ab7db6042d807ff",
            "476d52a08e2d49498c9551b4af069c58",
            "97a3e798433243a9a1d7b1089146da0f",
            "2b6f9d5e1eff47779a02284727f334b8",
            "97bd1c6695094b879787a9eeb96c3fbc",
            "bec58b29df7b4a038ad2907b718ca683",
            "6a63f753d34c4596988e35c182a828d1",
            "b4afd2810c64440a8af137f90bec34c2",
            "05f47e428a9e46168dd032502112a5dd",
            "677da5978e9a4bf4810f57b15479bb31",
            "d8269de3766a47bb879db513e2857d0c"
          ]
        },
        "id": "MPlBVpQd1SGB",
        "outputId": "e412d37c-4650-47fb-feaf-59bb316593c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:datasets.builder:Found cached dataset financial_phrasebank (/root/.cache/huggingface/datasets/financial_phrasebank/sentences_allagree/1.0.0/550bde12e6c30e2674da973a55f57edde5181d53f5a5a34c1531c53f93b7e141)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1b2fa5b90e2146039ab7db6042d807ff"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/2264 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1070: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "100%|██████████| 2264/2264 [05:03<00:00,  7.47it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tabulate import tabulate\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, precision_recall_fscore_support\n",
        "sentences = []\n",
        "labels = []\n",
        "preds = []\n",
        "with open('gpt-neo.csv', 'r') as file:\n",
        "    reader = csv.reader(file)\n",
        "    next(reader)  # skip the header row if there is one\n",
        "    for row in reader:\n",
        "        sentences.append(row[0])\n",
        "        labels.append(row[1])\n",
        "        preds.append(row[2])\n",
        "\n",
        "precision, recall, f1, support = precision_recall_fscore_support(labels, preds, average=None, zero_division=0)\n",
        "\n",
        "headers = [\"Class\", \"Precision\", \"Recall\", \"F1\", \"Support\"]\n",
        "data = []\n",
        "for i in range(3):\n",
        "    data.append([i, precision[i], recall[i], f1[i], support[i]])\n",
        "precision, recall, f1, support = precision_recall_fscore_support(labels, preds, average='weighted', zero_division=0)\n",
        "weighted_data = [\"weighted\", precision, recall, f1, support]\n",
        "data.append(weighted_data)\n",
        "precision, recall, f1, support = precision_recall_fscore_support(labels, preds, average='macro', zero_division=0)\n",
        "weighted_data = [\"macro\", precision, recall, f1, support]\n",
        "data.append(weighted_data)\n",
        "precision, recall, f1, support = precision_recall_fscore_support(labels, preds, average='micro', zero_division=0)\n",
        "weighted_data = [\"micro\", precision, recall, f1, support]\n",
        "data.append(weighted_data)\n",
        "\n",
        "name = 'gpt-neo.csv'\n",
        "\n",
        "experiment_name = f\"\\n\\nEXPERIMENT: {name}:\\n\"\n",
        "print(experiment_name)\n",
        "print(tabulate(data, headers=headers, tablefmt=\"fancy_grid\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fUtywKIi3uEh",
        "outputId": "fca8e42c-0743-459d-c7d4-68f4415f8c99"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "EXPERIMENT: gpt-neo.csv:\n",
            "\n",
            "╒══════════╤═════════════╤═══════════╤═══════════╤═══════════╕\n",
            "│ Class    │   Precision │    Recall │        F1 │   Support │\n",
            "╞══════════╪═════════════╪═══════════╪═══════════╪═══════════╡\n",
            "│ 0        │    0.06     │ 0.128713  │ 0.0818468 │       303 │\n",
            "├──────────┼─────────────┼───────────┼───────────┼───────────┤\n",
            "│ 1        │    0.855769 │ 0.0639827 │ 0.119064  │      1391 │\n",
            "├──────────┼─────────────┼───────────┼───────────┼───────────┤\n",
            "│ 2        │    0.306623 │ 0.812281  │ 0.445192  │       570 │\n",
            "├──────────┼─────────────┼───────────┼───────────┼───────────┤\n",
            "│ weighted │    0.611011 │ 0.261042  │ 0.196191  │           │\n",
            "├──────────┼─────────────┼───────────┼───────────┼───────────┤\n",
            "│ macro    │    0.407464 │ 0.334992  │ 0.215368  │           │\n",
            "├──────────┼─────────────┼───────────┼───────────┼───────────┤\n",
            "│ micro    │    0.261042 │ 0.261042  │ 0.261042  │           │\n",
            "╘══════════╧═════════════╧═══════════╧═══════════╧═══════════╛\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# change here for different experiments\n",
        "from datasets import load_dataset, DatasetDict\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, precision_recall_fscore_support\n",
        "experiments = [{\"path\": \"temp0.1_davinci.csv\", \"temp\": 0.1, \"model\": \"davinci\"},\n",
        "              {\"path\": \"temp0.2_davinci.csv\", \"temp\": 0.2, \"model\": \"davinci\"},\n",
        "               {\"path\": \"temp0.4_davinci.csv\", \"temp\": 0.4, \"model\": \"davinci\"}, ]\n",
        "              #{\"path\": \"temp0.6_davinci.csv\", \"temp\": 0.6, \"model\": \"davinci\"},\n",
        "               #{\"path\": \"temp0.8_davinci.csv\", \"temp\": 0.8, \"model\": \"davinci\"},]   \n",
        "               #{\"path\": \"temp0.2_curie.csv\", \"temp\": 0.2, \"model\": \"curie\"},    \n",
        "               #{\"path\": \"temp0.4_curie.csv\", \"temp\": 0.4, \"model\": \"curie\"},]    \n",
        "               #{\"path\": \"temp0.2_babbage.csv\", \"temp\": 0.2, \"model\": \"babbage\"},    \n",
        "               #{\"path\": \"temp0.4_babbage.csv\", \"temp\": 0.4, \"model\": \"babbage\"},]"
      ],
      "metadata": {
        "id": "fWfLuPUjIhGQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# dataset load               \n",
        "dataset = load_dataset('financial_phrasebank', 'sentences_allagree')\n",
        "train_size = 0\n",
        "valid_size = 0\n",
        "test_size = 1\n",
        "dataset_dict = DatasetDict({\n",
        "    'train': dataset['train'].select(range(int(len(dataset['train']) * train_size))),\n",
        "    'validation': dataset['train'].select(range(int(len(dataset['train']) * train_size), int(len(dataset['train']) * (train_size + valid_size)))),\n",
        "    'test': dataset['train'].select(range(int(len(dataset['train']) * (1 - test_size)), len(dataset['train'])))\n",
        "})\n",
        "\n",
        "#test\n",
        "for experiment in experiments:\n",
        "  preds = []\n",
        "  labels = []\n",
        "  sentence = []\n",
        "  for row in tqdm(dataset_dict['test']):\n",
        "      sentence.append(row['sentence'])\n",
        "      labels.append(row['label'])\n",
        "      preds.append(zero_shot_sentiment_analysis_GPT_3(row['sentence'],experiment['temp'],experiment['model']))\n",
        "\n",
        "  # Write the predictions and performance metrics to a CSV file\n",
        "  with open(experiment['path'], \"w\", newline=\"\") as f:\n",
        "      writer = csv.writer(f)\n",
        "      writer.writerow([\"sentence\", \"true_label\", \"pred_label\"])\n",
        "      for i in range(len(preds)):\n",
        "          writer.writerow([dataset_dict['test'][i]['sentence'], labels[i], preds[i]])"
      ],
      "metadata": {
        "id": "nw-l-5v9l5r3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tabulate import tabulate\n",
        "for experiment in tqdm(experiments):\n",
        "  sentences = []\n",
        "  labels = []\n",
        "  preds = []\n",
        "  with open(experiment['path'], 'r') as file:\n",
        "      reader = csv.reader(file)\n",
        "      next(reader)  # skip the header row if there is one\n",
        "      for row in reader:\n",
        "          sentences.append(row[0])\n",
        "          labels.append(row[1])\n",
        "          preds.append(row[2])\n",
        "\n",
        "  precision, recall, f1, support = precision_recall_fscore_support(labels, preds, average=None, zero_division=0)\n",
        "\n",
        "  headers = [\"Class\", \"Precision\", \"Recall\", \"F1\", \"Support\"]\n",
        "  data = []\n",
        "  for i in range(3):\n",
        "      data.append([i, precision[i], recall[i], f1[i], support[i]])\n",
        "  precision, recall, f1, support = precision_recall_fscore_support(labels, preds, average='weighted', zero_division=0)\n",
        "  weighted_data = [\"weighted\", precision, recall, f1, support]\n",
        "  data.append(weighted_data)\n",
        "  precision, recall, f1, support = precision_recall_fscore_support(labels, preds, average='macro', zero_division=0)\n",
        "  weighted_data = [\"macro\", precision, recall, f1, support]\n",
        "  data.append(weighted_data)\n",
        "  precision, recall, f1, support = precision_recall_fscore_support(labels, preds, average='micro', zero_division=0)\n",
        "  weighted_data = [\"micro\", precision, recall, f1, support]\n",
        "  data.append(weighted_data)\n",
        "  \n",
        "  name = experiment['path']\n",
        "\n",
        "  temp = name.split(\"_\")[0][4:]\n",
        "  model = name.split(\"_\")[1].split(\".\")[0].capitalize()\n",
        "\n",
        "  experiment_name = f\"\\n\\nEXPERIMENT: {model} temp = {temp}:\\n\"\n",
        "  print(experiment_name)\n",
        "  print(tabulate(data, headers=headers, tablefmt=\"fancy_grid\"))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MqV0pA-wxkyd",
        "outputId": "849cfc77-928a-4ce3-d89a-f7981a768974"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 40%|████      | 2/5 [00:00<00:00,  7.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "EXPERIMENT: Davinci temp = 0.1:\n",
            "\n",
            "╒══════════╤═════════════╤══════════╤══════════╤═══════════╕\n",
            "│ Class    │   Precision │   Recall │       F1 │   Support │\n",
            "╞══════════╪═════════════╪══════════╪══════════╪═══════════╡\n",
            "│ 0        │    0.940541 │ 0.574257 │ 0.713115 │       303 │\n",
            "├──────────┼─────────────┼──────────┼──────────┼───────────┤\n",
            "│ 1        │    0        │ 0        │ 0        │      1391 │\n",
            "├──────────┼─────────────┼──────────┼──────────┼───────────┤\n",
            "│ 2        │    0.269971 │ 0.984211 │ 0.423716 │       570 │\n",
            "├──────────┼─────────────┼──────────┼──────────┼───────────┤\n",
            "│ weighted │    0.193846 │ 0.324647 │ 0.202117 │           │\n",
            "├──────────┼─────────────┼──────────┼──────────┼───────────┤\n",
            "│ macro    │    0.403504 │ 0.519489 │ 0.378944 │           │\n",
            "├──────────┼─────────────┼──────────┼──────────┼───────────┤\n",
            "│ micro    │    0.324647 │ 0.324647 │ 0.324647 │           │\n",
            "╘══════════╧═════════════╧══════════╧══════════╧═══════════╛\n",
            "\n",
            "\n",
            "EXPERIMENT: Davinci temp = 0.2:\n",
            "\n",
            "╒══════════╤═════════════╤════════════╤════════════╤═══════════╕\n",
            "│ Class    │   Precision │     Recall │         F1 │   Support │\n",
            "╞══════════╪═════════════╪════════════╪════════════╪═══════════╡\n",
            "│ 0        │    0.898477 │ 0.584158   │ 0.708      │       303 │\n",
            "├──────────┼─────────────┼────────────┼────────────┼───────────┤\n",
            "│ 1        │    0.5      │ 0.00215672 │ 0.00429492 │      1391 │\n",
            "├──────────┼─────────────┼────────────┼────────────┼───────────┤\n",
            "│ 2        │    0.270742 │ 0.978947   │ 0.424173   │       570 │\n",
            "├──────────┼─────────────┼────────────┼────────────┼───────────┤\n",
            "│ weighted │    0.49561  │ 0.325972   │ 0.204186   │           │\n",
            "├──────────┼─────────────┼────────────┼────────────┼───────────┤\n",
            "│ macro    │    0.556407 │ 0.521754   │ 0.378823   │           │\n",
            "├──────────┼─────────────┼────────────┼────────────┼───────────┤\n",
            "│ micro    │    0.325972 │ 0.325972   │ 0.325972   │           │\n",
            "╘══════════╧═════════════╧════════════╧════════════╧═══════════╛\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|██████    | 3/5 [00:00<00:00,  7.61it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "EXPERIMENT: Davinci temp = 0.4:\n",
            "\n",
            "╒══════════╤═════════════╤═══════════╤═══════════╤═══════════╕\n",
            "│ Class    │   Precision │    Recall │        F1 │   Support │\n",
            "╞══════════╪═════════════╪═══════════╪═══════════╪═══════════╡\n",
            "│ 0        │    0.742081 │ 0.541254  │ 0.625954  │       303 │\n",
            "├──────────┼─────────────┼───────────┼───────────┼───────────┤\n",
            "│ 1        │    0.590909 │ 0.0280374 │ 0.0535347 │      1391 │\n",
            "├──────────┼─────────────┼───────────┼───────────┼───────────┤\n",
            "│ 2        │    0.276176 │ 0.957895  │ 0.42874   │       570 │\n",
            "├──────────┼─────────────┼───────────┼───────────┼───────────┤\n",
            "│ weighted │    0.531902 │ 0.33083   │ 0.224608  │           │\n",
            "├──────────┼─────────────┼───────────┼───────────┼───────────┤\n",
            "│ macro    │    0.536389 │ 0.509062  │ 0.36941   │           │\n",
            "├──────────┼─────────────┼───────────┼───────────┼───────────┤\n",
            "│ micro    │    0.33083  │ 0.33083   │ 0.33083   │           │\n",
            "╘══════════╧═════════════╧═══════════╧═══════════╧═══════════╛\n",
            "\n",
            "\n",
            "EXPERIMENT: Davinci temp = 0.6:\n",
            "\n",
            "╒══════════╤═════════════╤══════════╤══════════╤═══════════╕\n",
            "│ Class    │   Precision │   Recall │       F1 │   Support │\n",
            "╞══════════╪═════════════╪══════════╪══════════╪═══════════╡\n",
            "│ 0        │    0.505618 │ 0.29703  │ 0.37422  │       303 │\n",
            "├──────────┼─────────────┼──────────┼──────────┼───────────┤\n",
            "│ 1        │    0.594022 │ 0.342919 │ 0.434822 │      1391 │\n",
            "├──────────┼─────────────┼──────────┼──────────┼───────────┤\n",
            "│ 2        │    0.278254 │ 0.626316 │ 0.385321 │       570 │\n",
            "├──────────┼─────────────┼──────────┼──────────┼───────────┤\n",
            "│ weighted │    0.502691 │ 0.408127 │ 0.414249 │           │\n",
            "├──────────┼─────────────┼──────────┼──────────┼───────────┤\n",
            "│ macro    │    0.459298 │ 0.422088 │ 0.398121 │           │\n",
            "├──────────┼─────────────┼──────────┼──────────┼───────────┤\n",
            "│ micro    │    0.408127 │ 0.408127 │ 0.408127 │           │\n",
            "╘══════════╧═════════════╧══════════╧══════════╧═══════════╛\n",
            "\n",
            "\n",
            "EXPERIMENT: Davinci temp = 0.8:\n",
            "\n",
            "╒══════════╤═════════════╤══════════╤══════════╤═══════════╕\n",
            "│ Class    │   Precision │   Recall │       F1 │   Support │\n",
            "╞══════════╪═════════════╪══════════╪══════════╪═══════════╡\n",
            "│ 0        │    0.399225 │ 0.339934 │ 0.367201 │       303 │\n",
            "├──────────┼─────────────┼──────────┼──────────┼───────────┤\n",
            "│ 1        │    0.612602 │ 0.377426 │ 0.467082 │      1391 │\n",
            "├──────────┼─────────────┼──────────┼──────────┼───────────┤\n",
            "│ 2        │    0.281984 │ 0.568421 │ 0.376963 │       570 │\n",
            "├──────────┼─────────────┼──────────┼──────────┼───────────┤\n",
            "│ weighted │    0.500806 │ 0.420495 │ 0.431026 │           │\n",
            "├──────────┼─────────────┼──────────┼──────────┼───────────┤\n",
            "│ macro    │    0.43127  │ 0.428594 │ 0.403749 │           │\n",
            "├──────────┼─────────────┼──────────┼──────────┼───────────┤\n",
            "│ micro    │    0.420495 │ 0.420495 │ 0.420495 │           │\n",
            "╘══════════╧═════════════╧══════════╧══════════╧═══════════╛"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5/5 [00:00<00:00,  8.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    }
  ]
}